.intel_syntax noprefix

.section .rodata

.set pbits,2047
.set pbytes,320
.set plimbs,32


.global secsidh_internal_2047k221_p
secsidh_internal_2047k221_p:
.long 0x3FFFFFF,0x3FFFFFF,0x3FFFFFF,0x3FFFFFF 
.long 0xC90A04,0x3455C4E,0x30C3714,0x103B3F1 
.long 0x27D3254,0x1B16817,0x26D6CAC,0x7F868B 
.long 0x358F1F6,0x2DFD2E3,0x2D1A549,0x1BAEB97 
.long 0x2D3630A,0xADB83D,0x3769AE6,0x311E2B 
.long 0x2BC56CE,0x20D7DE3,0xC2B097,0x4391BA 
.long 0x1D1D513,0x95E6C9,0x3FC6C6B,0x1859037 
.long 0xFAB37D,0x258A4FD,0x1E3B7B9,0x2B14DC5 
.long 0x27800A6,0x12079E4,0x225BA90,0x37DEAB9 
.long 0x89A678,0x26C314C,0xD51D75,0xF2AE11 
.long 0x1A706EB,0x281605B,0x28C5352,0x1EBE86B 
.long 0x15F8C45,0x3256B7,0x1490C34,0x2FB65F2 
.long 0x143B329,0x26C292D,0x33A2B91,0x37EB001 
.long 0x31BF721,0x3039EAA,0x2B31776,0x38D0C45 
.long 0x156241F,0x1345530,0xCE8AD5,0x1A658B4 
.long 0x303859D,0x1B620AB,0x3740C2,0x270F03F 
.long 0x103A02B,0x351CAA8,0x378BDEB,0x1281D20 
.long 0x325D9E2,0x3D9DC97,0x5AFE27,0x2C6D272 
.long 0x384C9B3,0xBBFE7F,0x36FD073,0x2EE5370 
.long 0x2EFB626,0x2BC9B92,0x4F49A,0x0

.global secsidh_internal_2047k221_inv_min_p_mod_r
secsidh_internal_2047k221_inv_min_p_mod_r:
.long 0x1,0x0,0x0,0x0 
.long 0xC90A05,0x3455C4E,0x30C3714,0x103B3F1 
.long 0x2BB966D,0x409352,0x33A1658,0xD46A37 
.long 0x171DE14,0x1D3AF4B,0x2AB6873,0x1297FFC 
.long 0x23EA1E7,0x13A2D8C,0x2D22069,0x1E22551 
.long 0x29417BC,0x147D776,0x28222CE,0x53717 
.long 0x22F8827,0x1595D11,0xC8FC11,0x29DA322 
.long 0x2D05FDD,0x3AFDF86,0xCFB957,0x10C474 
.long 0x2AE01E1,0x1103C4F,0x74C37F,0x22DE26E 
.long 0x17BA58B,0x265453F,0x8B6C33,0x1F81712 
.long 0x2EFA339,0x2C98E7,0x355BE38,0x3896A82 
.long 0x179A45A,0x87A4AD,0x249F818,0x154DB2E 
.long 0x246272B,0x368B87B,0x2A68143,0x12BEB9D 
.long 0x3A5D173,0x2BA41DB,0x558C34,0xB22389 
.long 0x73BB28,0x332E7F6,0xF82401,0x9B3A11 
.long 0x2D14325,0x1C85065,0x13DEAD1,0x229C90F 
.long 0x97F63D,0xD95405,0x4AD3DC,0x32B487D 
.long 0xE95848,0x10819FC,0xAA838E,0x10C372D 
.long 0x6F5ED4,0x3088150,0x3711676,0x37608AD 
.long 0x3ECE557,0x35ADED9,0x1830CE0,0x1419F8F 



.global secsidh_internal_2047k221_fp_0
secsidh_internal_2047k221_fp_0:
.zero pbytes


.global secsidh_internal_2047k221_fp_1
secsidh_internal_2047k221_fp_1:
.long 0x28F0DD0,0xCE,0x0,0x0 
.long 0x5A9AF0,0x1C5FBB,0x3334BBD,0x17421AD 
.long 0x2BE95A,0x6324FA,0x2A7F510,0x34DA6AB 
.long 0x1811C0,0x1EB3C2E,0x8B9747,0x5045C8 
.long 0x1D1BA1,0x83C2AF,0x3111487,0x1E27F4E 
.long 0x1D94F9D,0x8A54C9,0x5464BC,0x2A681DF 
.long 0x3896C5C,0x131D404,0x2A1DF8F,0x2C305FA 
.long 0x1EA901F,0x1E94ADA,0x37A5544,0x17F884D 
.long 0x157836D,0x2EB91B0,0x3947B2C,0x1B31B15 
.long 0x1DEE40,0x10712E5,0x161B7C6,0x276AC15 
.long 0x1C82219,0x2B1E963,0x13D4FC7,0x134627A 
.long 0x2A3D3C5,0x2B57DAF,0x1597691,0x3C7917F 
.long 0x2C9F7EF,0x29B04A0,0x3F16304,0xB26281 
.long 0x21D9195,0x28C688D,0x8AA98D,0x1648DCC 
.long 0x116AEE2,0x32B691E,0x3459764,0x312F204 
.long 0x1BDE97E,0x14B645,0x2CCF8DC,0x23F24F0 
.long 0x3759538,0xD7D733,0x20B11D4,0x3AC5AC2 
.long 0xEBA14C,0x1F7453B,0x19A5B05,0x2A47FEB 
.long 0x31CF90E,0x1493B0B,0x194BE15,0x262F6DC 
.long 0x1AF250,0x187BD4E,0x212D6,0x0 



.global secsidh_internal_2047k221_fp_2
secsidh_internal_2047k221_fp_2:
.long 0x11E1BA0,0x19D,0x0,0x0 
.long 0xB535E0,0x38BF76,0x266977A,0x2E8435B 
.long 0x57D2B4,0xC649F4,0x14FEA20,0x29B4D57 
.long 0x302381,0x3D6785C,0x1172E8E,0xA08B90 
.long 0x3A3742,0x107855E,0x222290E,0x3C4FE9D 
.long 0x3B29F3A,0x114A992,0xA8C978,0x14D03BE 
.long 0x312D8B9,0x263A809,0x143BF1E,0x1860BF5 
.long 0x3D5203F,0x3D295B4,0x2F4AA88,0x2FF109B 
.long 0x2AF06DA,0x1D72360,0x328F659,0x366362B 
.long 0x3BDC80,0x20E25CA,0x2C36F8C,0xED582A 
.long 0x3904433,0x163D2C6,0x27A9F8F,0x268C4F4 
.long 0x147A78A,0x16AFB5F,0x2B2ED23,0x38F22FE 
.long 0x193EFDF,0x1360941,0x3E2C609,0x164C503 
.long 0x3B232A,0x118D11B,0x115531B,0x2C91B98 
.long 0x22D5DC4,0x256D23C,0x28B2EC9,0x225E409 
.long 0x37BD2FD,0x296C8A,0x199F1B8,0x7E49E1 
.long 0x2EB2A71,0x1AFAE67,0x1623A8,0x358B585 
.long 0x1D74299,0x3EE8A76,0x334B60A,0x148FFD6 
.long 0x239F21D,0x2927617,0x3297C2A,0xC5EDB8 
.long 0x35E4A1,0x30F7A9C,0x425AC,0x0 



.global secsidh_internal_2047k221_r_squared_mod_p
secsidh_internal_2047k221_r_squared_mod_p:
.long 0x255B135,0x2918380,0x2ED3DFE,0x1A6414C 
.long 0x3E90AAF,0x123B14B,0x1C3DBF6,0x2AC4553 
.long 0x1A398FC,0x2EB9F02,0x1C30AF6,0x23771C4 
.long 0x1B7DFBF,0x3BEBB89,0x13A8798,0x35442FF 
.long 0x12C27D7,0x19CCC7C,0x2A160C9,0x14C59D 
.long 0x22CC71A,0x2D5D2EA,0x29EDCF1,0x5D1574 
.long 0x7882E2,0x1524E59,0x28CBB5B,0x13BE71 
.long 0x2BD3B97,0xBBBAA4,0x197AB50,0x31A3C48 
.long 0x30BB31C,0x2A043BF,0x2D653F3,0x3388AED 
.long 0x1F7189B,0x2ADCCCC,0x2F6259E,0x3D59FEF 
.long 0x382C281,0x65226D,0x1DAB50E,0x337F678 
.long 0x7F3F70,0x1B53ABF,0x1BF69B0,0x3C6BF97 
.long 0x7E8B3A,0x2F7258D,0x39A8AE4,0xF58694 
.long 0x7B0A61,0xCADFC7,0x22BB2E2,0x18289DE 
.long 0x14F5D74,0x388FE59,0x2F33BF8,0x96C2C7 
.long 0x2D4D9A1,0x1B97F41,0x34E04E3,0x37B6190 
.long 0x1BF81AD,0x1AC3B37,0x1541DB1,0x149B0B8 
.long 0x7A2D71,0x1C9B952,0xB15466,0x226391B 
.long 0x1F409A6,0x180EB70,0xEE2A75,0x21AA5ED 
.long 0x211A26D,0x159BC8D,0x7C56,0x0 



.global secsidh_internal_2047k221_p_minus_2
secsidh_internal_2047k221_p_minus_2:
.long 0x3FFFFFD,0x3FFFFFF,0x3FFFFFF,0x3FFFFFF 
.long 0xC90A04,0x3455C4E,0x30C3714,0x103B3F1 
.long 0x27D3254,0x1B16817,0x26D6CAC,0x7F868B 
.long 0x358F1F6,0x2DFD2E3,0x2D1A549,0x1BAEB97 
.long 0x2D3630A,0xADB83D,0x3769AE6,0x311E2B 
.long 0x2BC56CE,0x20D7DE3,0xC2B097,0x4391BA 
.long 0x1D1D513,0x95E6C9,0x3FC6C6B,0x1859037 
.long 0xFAB37D,0x258A4FD,0x1E3B7B9,0x2B14DC5 
.long 0x27800A6,0x12079E4,0x225BA90,0x37DEAB9 
.long 0x89A678,0x26C314C,0xD51D75,0xF2AE11 
.long 0x1A706EB,0x281605B,0x28C5352,0x1EBE86B 
.long 0x15F8C45,0x3256B7,0x1490C34,0x2FB65F2 
.long 0x143B329,0x26C292D,0x33A2B91,0x37EB001 
.long 0x31BF721,0x3039EAA,0x2B31776,0x38D0C45 
.long 0x156241F,0x1345530,0xCE8AD5,0x1A658B4 
.long 0x303859D,0x1B620AB,0x3740C2,0x270F03F 
.long 0x103A02B,0x351CAA8,0x378BDEB,0x1281D20 
.long 0x325D9E2,0x3D9DC97,0x5AFE27,0x2C6D272 
.long 0x384C9B3,0xBBFE7F,0x36FD073,0x2EE5370 
.long 0x2EFB626,0x2BC9B92,0x4F49A,0x0 



.global secsidh_internal_2047k221_p_minus_1_halves
secsidh_internal_2047k221_p_minus_1_halves:
.long 0x3FFFFFF,0x3FFFFFF,0x3FFFFFF,0x1FFFFFF 
.long 0x648502,0x1A2AE27,0x3861B8A,0x81D9F8 
.long 0x33E992A,0xD8B40B,0x336B656,0x3FC345 
.long 0x3AC78FB,0x36FE971,0x368D2A4,0xDD75CB 
.long 0x369B185,0x56DC1E,0x3BB4D73,0x188F15 
.long 0x35E2B67,0x306BEF1,0x61584B,0x221C8DD 
.long 0x2E8EA89,0x24AF364,0x3FE3635,0x2C2C81B 
.long 0x27D59BE,0x32C527E,0x2F1DBDC,0x158A6E2 
.long 0x13C0053,0x903CF2,0x312DD48,0x1BEF55C 
.long 0x44D33C,0x33618A6,0x26A8EBA,0x2795708 
.long 0x2D38375,0x140B02D,0x34629A9,0x2F5F435 
.long 0x2AFC622,0x192B5B,0xA4861A,0x37DB2F9 
.long 0x2A1D994,0x3361496,0x39D15C8,0x3BF5800 
.long 0x18DFB90,0x181CF55,0x3598BBB,0x3C68622 
.long 0xAB120F,0x29A2A98,0x67456A,0x2D32C5A 
.long 0x381C2CE,0xDB1055,0x21BA061,0x338781F 
.long 0x81D015,0x3A8E554,0x1BC5EF5,0x940E90 
.long 0x392ECF1,0x3ECEE4B,0x2D7F13,0x3636939 
.long 0x3C264D9,0x25DFF3F,0x1B7E839,0x17729B8 
.long 0x177DB13,0x15E4DC9,0x27A4D,0x0 



.global secsidh_internal_2047k221_p_minus_3_quarters
secsidh_internal_2047k221_p_minus_3_quarters:
.long 0x3FFFFFF,0x3FFFFFF,0x3FFFFFF,0xFFFFFF 
.long 0x2324281,0xD15713,0x1C30DC5,0x40ECFC 
.long 0x39F4C95,0x6C5A05,0x39B5B2B,0x21FE1A2 
.long 0x3D63C7D,0x1B7F4B8,0x3B46952,0x26EBAE5 
.long 0x1B4D8C2,0x22B6E0F,0x3DDA6B9,0x20C478A 
.long 0x3AF15B3,0x3835F78,0x230AC25,0x310E46E 
.long 0x1747544,0x32579B2,0x3FF1B1A,0x161640D 
.long 0x13EACDF,0x196293F,0x178EDEE,0x2AC5371 
.long 0x9E0029,0x481E79,0x1896EA4,0xDF7AAE 
.long 0x22699E,0x19B0C53,0x135475D,0x33CAB84 
.long 0x369C1BA,0x2A05816,0x3A314D4,0x17AFA1A 
.long 0x357E311,0xC95AD,0x252430D,0x1BED97C 
.long 0x150ECCA,0x19B0A4B,0x1CE8AE4,0x1DFAC00 
.long 0x2C6FDC8,0x2C0E7AA,0x1ACC5DD,0x3E34311 
.long 0x558907,0x14D154C,0x33A2B5,0x169962D 
.long 0x3C0E167,0x26D882A,0x30DD030,0x39C3C0F 
.long 0x40E80A,0x3D472AA,0xDE2F7A,0x24A0748 
.long 0x3C97678,0x3F67725,0x216BF89,0x3B1B49C 
.long 0x3E1326C,0x32EFF9F,0xDBF41C,0x2BB94DC 
.long 0x2BBED89,0x2AF26E4,0x13D26,0x0


.align 32
.SHUFFLE_MUL:
        .quad   17179869184                     # 0x400000000
        .quad   21474836481                     # 0x500000001
        .quad   25769803778                     # 0x600000002
        .quad   30064771075                     # 0x700000003

.SHUFFLE_CARRY:
        .quad   7                               # 0x000000007
        .quad   8589934593                      # 0x200000001
        .quad   17179869187                     # 0x400000003
        .quad   25769803781                     # 0x600000005

.ZERO_1ST_MASK:
        .long   0x0,0xffffffff
        .quad   0xffffffffffffffff
        .quad   0xffffffffffffffff
        .quad   0xffffffffffffffff

.base:
        .quad   67108863                        # 0x3ffffff

.number2:    .long 67108863


.section .text


.global secsidh_internal_2047k221_fp_copy
secsidh_internal_2047k221_fp_copy:
    vmovdqa ymm15, YMMWORD PTR [rsi + 0*32]
    vmovdqa YMMWORD PTR [rdi + 0*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 1*32]
    vmovdqa YMMWORD PTR [rdi + 1*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 2*32]
    vmovdqa YMMWORD PTR [rdi + 2*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 3*32]
    vmovdqa YMMWORD PTR [rdi + 3*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 4*32]
    vmovdqa YMMWORD PTR [rdi + 4*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 5*32]
    vmovdqa YMMWORD PTR [rdi + 5*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 6*32]
    vmovdqa YMMWORD PTR [rdi + 6*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 7*32]
    vmovdqa YMMWORD PTR [rdi + 7*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 8*32]
    vmovdqa YMMWORD PTR [rdi + 8*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 9*32]
    vmovdqa YMMWORD PTR [rdi + 9*32], ymm15
    vzeroupper
    ret

.global secsidh_internal_2047k221_OneTimeCarry
secsidh_internal_2047k221_OneTimeCarry:
    vmovdqa ymm15, YMMWORD PTR [rsi + 0*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 0*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 1*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 1*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 2*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 2*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 3*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 3*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 4*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 4*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 5*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 5*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 6*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 6*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 7*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 7*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 8*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 8*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rsi + 9*32]
    vpbroadcastq ymm0, qword ptr [rip + .base]
    vpand ymm1, ymm15, ymm0
    vpandn ymm15, ymm0, ymm15
    vpsrlq ymm15, ymm15, 26
    vpaddq ymm15, ymm15, ymm1
    vmovdqa YMMWORD PTR [rdi + 9*32], ymm15
    ret

.global secsidh_internal_2047k221_p_times_w
secsidh_internal_2047k221_p_times_w:
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

    vmovd xmm0, edx
    vpbroadcastd ymm0, xmm0
    vmovdqa ymm1, ymmword ptr [rip + .SHUFFLE_MUL]
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 0*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 0*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 1*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 1*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 2*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 3*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 2*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 4*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 5*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 3*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 6*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 7*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 4*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 8*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 9*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 5*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 10*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 11*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 6*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 12*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 13*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 7*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 14*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 15*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 8*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 16*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 17*32] , ymm12
#############################
    vmovdqa ymm15, YMMWORD PTR [esi + 9*32]
    vpermd ymm15, ymm1, ymm15
    vpmuldq ymm11 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 18*32] , ymm11
    vpshufd ymm15, ymm15, 177
    vpmuldq ymm12 , ymm15, ymm0
    vmovdqa ymmword ptr [rdi + 19*32] , ymm12
#############################
    vzeroupper
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

   ret

.global secsidh_internal_2047k221_a_plus_u_i
secsidh_internal_2047k221_a_plus_u_i:
    vmovdqa ymm15, YMMWORD PTR [rdi + 0*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 0*32]
    vmovdqa YMMWORD PTR [rdi + 0*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 1*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 1*32]
    vmovdqa YMMWORD PTR [rdi + 1*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 2*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 2*32]
    vmovdqa YMMWORD PTR [rdi + 2*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 3*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 3*32]
    vmovdqa YMMWORD PTR [rdi + 3*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 4*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 4*32]
    vmovdqa YMMWORD PTR [rdi + 4*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 5*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 5*32]
    vmovdqa YMMWORD PTR [rdi + 5*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 6*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 6*32]
    vmovdqa YMMWORD PTR [rdi + 6*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 7*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 7*32]
    vmovdqa YMMWORD PTR [rdi + 7*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 8*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 8*32]
    vmovdqa YMMWORD PTR [rdi + 8*32], ymm15
    vmovdqa ymm15, YMMWORD PTR [rdi + 9*32]
    vpaddd ymm15 , ymm15, ymmword ptr [rsi + 9*32]
    vmovdqa YMMWORD PTR [rdi + 9*32], ymm15
    vzeroupper
    ret





.global secsidh_internal_2047k221_sub_avx2
secsidh_internal_2047k221_sub_avx2:
        vmovdqa ymm0, ymmword ptr [rsi]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 32]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 96]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 256]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 288]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vzeroupper
        ret


.global secsidh_internal_2047k221_add_avx2
secsidh_internal_2047k221_add_avx2:
        vmovdqa ymm0, ymmword ptr [rdx]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 32]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 256]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 288]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vzeroupper
        ret


.global secsidh_internal_2047k221_add_2x_2x2_avx2
secsidh_internal_2047k221_add_2x_2x2_avx2:
        vmovdqa ymm0, ymmword ptr [rsi + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 0]
        vmovdqa ymmword ptr [rdi + 0], ymm0
        vmovdqa ymm1, ymmword ptr [rdx + 64]
        vpaddd  ymm1, ymm1, ymmword ptr [rdx + 0]
        vmovdqa ymmword ptr [rdi + 64], ymm1
        vmovdqa ymm0, ymmword ptr [rsi + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm1, ymmword ptr [rdx + 96]
        vpaddd  ymm1, ymm1, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 96], ymm1
    ret


.global secsidh_internal_2047k221_interleave
secsidh_internal_2047k221_interleave:
        vmovdqa ymm5, YMMWORD PTR [rdx]
        vmovdqa ymm7, YMMWORD PTR [r8]
        vperm2i128      ymm3, ymm5, YMMWORD PTR [rsi], 2
        vperm2i128      ymm2, ymm7, YMMWORD PTR [rcx], 2
        vperm2i128      ymm1, ymm5, YMMWORD PTR [rsi], 19
        vperm2i128      ymm0, ymm7, YMMWORD PTR [rcx], 19
        vpermq  ymm3, ymm3, 216
        vpermq  ymm2, ymm2, 216
        vpermq  ymm1, ymm1, 216
        vperm2i128      ymm4, ymm2, ymm3, 2
        vpermq  ymm0, ymm0, 216
        vperm2i128      ymm2, ymm2, ymm3, 19
        vmovdqa YMMWORD PTR [rdi], ymm4
        vmovdqa YMMWORD PTR [rdi+32], ymm2
        vperm2i128      ymm2, ymm0, ymm1, 2
        vperm2i128      ymm0, ymm0, ymm1, 19
        vmovdqa YMMWORD PTR [rdi+64], ymm2
        vmovdqa YMMWORD PTR [rdi+96], ymm0
        vmovdqa ymm1, YMMWORD PTR [rdx+32]
        vmovdqa ymm0, YMMWORD PTR [r8+32]
        vperm2i128      ymm1, ymm1, YMMWORD PTR [rsi+32], 2
        vperm2i128      ymm0, ymm0, YMMWORD PTR [rcx+32], 2
        vpermq  ymm1, ymm1, 216
        vpermq  ymm0, ymm0, 216
        vperm2i128      ymm0, ymm0, ymm1, 2
        vmovdqa YMMWORD PTR [rdi+128], ymm0
        vzeroupper
        ret


.global secsidh_internal_2047k221_deinterleave
secsidh_internal_2047k221_deinterleave:
        vmovdqa ymm0, ymmword ptr [rdi + 32]
        vpsllq  ymm0, ymm0, 32
        vpxor   ymm0, ymm0, ymmword ptr [rdi]
        vmovdqa ymm1, ymmword ptr [rdi + 96]
        vpsllq  ymm1, ymm1, 32
        vpxor   ymm1, ymm1, ymmword ptr [rdi + 64]
        vmovdqa ymm2, ymmword ptr [rdi + 160]
        vpsllq  ymm2, ymm2, 32
        vpxor   ymm2, ymm2, ymmword ptr [rdi + 128]
        vmovdqa ymm3, ymmword ptr [rdi + 224]
        vpsllq  ymm3, ymm3, 32
        vpxor   ymm3, ymm3, ymmword ptr [rdi + 192]
        vinserti128     ymm4, ymm0, xmm1, 1
        vmovdqa ymmword ptr [rsi], ymm4
        vperm2i128      ymm0, ymm0, ymm1, 49    # ymm0 = ymm0[2,3],ymm1[2,3]
        vmovdqa ymmword ptr [rdx], ymm0
        vinserti128     ymm0, ymm2, xmm3, 1
        vmovdqa ymmword ptr [rcx], ymm0
        vperm2i128      ymm0, ymm2, ymm3, 49    # ymm0 = ymm2[2,3],ymm3[2,3]
        vmovdqa ymmword ptr [r8], ymm0
        vpermpd ymm1, ymmword ptr [rsi], 216    # ymm1 = mem[0,2,1,3]
        vpermq  ymm2, ymmword ptr [rdx], 216    # ymm2 = mem[0,2,1,3]
        vpermpd ymm3, ymmword ptr [rcx], 216    # ymm3 = mem[0,2,1,3]
        vpermq  ymm0, ymm0, 216                 # ymm0 = ymm0[0,2,1,3]
        vinsertf128     ymm4, ymm1, xmm3, 1
        vmovaps ymmword ptr [rsi], ymm4
        vperm2f128      ymm1, ymm1, ymm3, 49    # ymm1 = ymm1[2,3],ymm3[2,3]
        vmovaps ymmword ptr [rdx], ymm1
        vinserti128     ymm1, ymm2, xmm0, 1
        vmovdqa ymmword ptr [rcx], ymm1
        vperm2i128      ymm0, ymm2, ymm0, 49    # ymm0 = ymm2[2,3],ymm0[2,3]
        vmovdqa ymmword ptr [r8], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 288]
        vpsllq  ymm0, ymm0, 32
        vpxor   ymm0, ymm0, ymmword ptr [rdi + 256]
        vmovq   xmm1, xmm0                      # xmm1 = xmm0[0],zero
        vmovdqa ymmword ptr [rsi + 32], ymm1
 #       vpsrldq xmm1, xmm0, 8                   # xmm1 = xmm0[8,9,10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero
        vpsrldq xmm1, xmm0, 8                   # xmm1 = xmm0[8,9,10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero

        vmovdqa ymmword ptr [rdx + 32], ymm1
        vextracti128    xmm1, ymm0, 1
        vmovq   xmm1, xmm1                      # xmm1 = xmm1[0],zero
        vmovdqa ymmword ptr [rcx + 32], ymm1
        vpermq  ymm0, ymm0, 255                 # ymm0 = ymm0[3,3,3,3]
        vmovq   xmm0, xmm0                      # xmm0 = xmm0[0],zero
        vmovdqa ymmword ptr [r8 + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 352]
        vmovdqa ymm1, ymmword ptr [rdi + 416]
        vmovdqa ymm2, ymmword ptr [rdi + 480]
        vpsllq  ymm0, ymm0, 32
        vpxor   ymm0, ymm0, ymmword ptr [rdi + 320]
        vmovdqa ymm3, ymmword ptr [rdi + 544]
        vpsllq  ymm1, ymm1, 32
        vpxor   ymm1, ymm1, ymmword ptr [rdi + 384]
        vpsllq  ymm2, ymm2, 32
        vpxor   ymm2, ymm2, ymmword ptr [rdi + 448]
        vpsllq  ymm3, ymm3, 32
        vpxor   ymm3, ymm3, ymmword ptr [rdi + 512]
        vinserti128     ymm4, ymm0, xmm1, 1
        vmovdqa ymmword ptr [rsi + 64], ymm4
        vperm2i128      ymm0, ymm0, ymm1, 49    # ymm0 = ymm0[2,3],ymm1[2,3]
        vmovdqa ymmword ptr [rdx + 64], ymm0
        vinserti128     ymm0, ymm2, xmm3, 1
        vmovdqa ymmword ptr [rcx + 64], ymm0
        vperm2i128      ymm0, ymm2, ymm3, 49    # ymm0 = ymm2[2,3],ymm3[2,3]
        vmovdqa ymmword ptr [r8 + 64], ymm0
        vpermpd ymm1, ymmword ptr [rsi + 64], 216 # ymm1 = mem[0,2,1,3]
        vpermq  ymm2, ymmword ptr [rdx + 64], 216 # ymm2 = mem[0,2,1,3]
        vpermpd ymm3, ymmword ptr [rcx + 64], 216 # ymm3 = mem[0,2,1,3]
        vpermq  ymm0, ymm0, 216                 # ymm0 = ymm0[0,2,1,3]
        vinsertf128     ymm4, ymm1, xmm3, 1
        vmovaps ymmword ptr [rsi + 64], ymm4
        vperm2f128      ymm1, ymm1, ymm3, 49    # ymm1 = ymm1[2,3],ymm3[2,3]
        vmovaps ymmword ptr [rdx + 64], ymm1
        vinserti128     ymm1, ymm2, xmm0, 1
        vmovdqa ymmword ptr [rcx + 64], ymm1
        vperm2i128      ymm0, ymm2, ymm0, 49    # ymm0 = ymm2[2,3],ymm0[2,3]
        vmovdqa ymmword ptr [r8 + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 608]
        vpsllq  ymm0, ymm0, 32
        vpxor   ymm0, ymm0, ymmword ptr [rdi + 576]
        vmovq   xmm1, xmm0                      # xmm1 = xmm0[0],zero
        vmovdqa ymmword ptr [rsi + 96], ymm1
#        vpsrldq xmm1, xmm0, 8                   # xmm1 = xmm0[8,9,10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero
        vpsrldq xmm1, xmm0, 8                   # xmm1 = xmm0[8,9,10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero
        vmovdqa ymmword ptr [rdx + 96], ymm1
        vextracti128    xmm1, ymm0, 1
        vmovq   xmm1, xmm1                      # xmm1 = xmm1[0],zero
        vmovdqa ymmword ptr [rcx + 96], ymm1
        vpermq  ymm0, ymm0, 255                 # ymm0 = ymm0[3,3,3,3]
        vmovq   xmm0, xmm0                      # xmm0 = xmm0[0],zero
        vmovdqa ymmword ptr [r8 + 96], ymm0
        vzeroupper
        ret

.global secsidh_internal_2047k221_carry32_avx2
secsidh_internal_2047k221_carry32_avx2:
    xor     eax, eax
    sal     rsi, 5
    vmovdqa ymm7, ymmword ptr [rip + .SHUFFLE_CARRY]
    vmovdqa ymm8, ymmword ptr [rip + .ZERO_1ST_MASK]
    vpbroadcastd  ymm0, dword ptr [rip + .base]
    vpxor ymm4, ymm4, ymm4
LOOP:
    # ymm1 = next vector of limbs
    vmovdqa ymm1, ymmword ptr [rdi+rax]
    
    # ymm2 = carry
    # vpsrld  ymm2, ymm1, 26
    vpsrad  ymm2, ymm1, 26

    # ymm1 = mask radix
    vpand   ymm1, ymm1, ymm0
    
    # ymm2 = "shift" carry <- 1
    vpermd  ymm2, ymm7, ymm2
    
    # ymm3 = zero the least significant limb
    vpand   ymm3, ymm2, ymm8

    # ymm1 = ymm1 + carry
    vpaddd  ymm1, ymm1, ymm3
    
    # ymm1 = ymm1 + ymm4 ~ single "carry-limb" from last step
    vpaddd  ymm1, ymm1, ymm4
    
    # ymm4 = carry for next step
    vpandn  ymm4, ymm8, ymm2

    vmovdqa ymmword ptr [rdi+rax], ymm1
    add     rax, 32
    cmp     rsi, rax
    jne     LOOP
    ret

.global secsidh_internal_2047k221_mult_interl
secsidh_internal_2047k221_mult_interl:
############## load as much a's as possible
    vmovdqa ymm0, YMMWORD PTR [rsi + 0] 
    vmovdqa ymm1, YMMWORD PTR [rsi + 32] 
    vmovdqa ymm2, YMMWORD PTR [rsi + 64] 


############## load    b_0
    vmovdqa ymm15, YMMWORD PTR [rdx + 0] 
############## w/o adds
############## a_0 * b_0
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm12 , ymm15, ymm0
############## a_1 * b_0
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm11 , ymm15, ymm0
############## a_2 * b_0
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm10 , ymm15, ymm1
############## a_3 * b_0
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm9 , ymm15, ymm1
############## a_4 * b_0
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm8 , ymm15, ymm2
############## a_5 * b_0
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm7 , ymm15, ymm2
############## a_6 * b_0
############## read from stack
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
############## load    a_6
    vpmuldq ymm6, ymm15, ymm13
############## a_7 * b_0
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm5, ymm15, ymm13
############## a_8 * b_0
############## read from stack
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
############## load    a_8
    vpmuldq ymm4, ymm15, ymm13
############## a_9 * b_0
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm3, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 0], ymm12


############## perm to b_1
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_1
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm10, ymm14, ymm10 
############## a_0 * b_1
############## read from regs
############## perm ymm0 to a_0
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm11, ymm14, ymm11 
############## a_3 * b_1
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm8, ymm14, ymm8 
############## a_2 * b_1
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm9, ymm14, ymm9 
############## a_5 * b_1
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm6, ymm14, ymm6 
############## a_4 * b_1
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm7, ymm14, ymm7 
############## a_6 * b_1
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm5, ymm14, ymm5
############## a_7 * b_1
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm4, ymm14, ymm4
############## a_8 * b_1
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm3, ymm14, ymm3
############## a_9 * b_1
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm12, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 32] , ymm11


############## load    b_2
    vmovdqa ymm15, YMMWORD PTR [rdx + 32] 
############## perm = False
############## w/ adds
############## a_0 * b_2
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm10, ymm14, ymm10 
############## a_1 * b_2
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm9, ymm14, ymm9 
############## a_2 * b_2
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm8, ymm14, ymm8 
############## a_3 * b_2
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm7, ymm14, ymm7 
############## a_4 * b_2
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm6, ymm14, ymm6 
############## a_5 * b_2
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm5, ymm14, ymm5 
############## a_6 * b_2
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm4, ymm14, ymm4
############## a_7 * b_2
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm3, ymm14, ymm3
############## a_8 * b_2
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm12, ymm14, ymm12
############## a_9 * b_2
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm11, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 64] , ymm10


############## perm to b_3
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_3
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm8, ymm14, ymm8 
############## a_0 * b_3
############## read from regs
############## perm ymm0 to a_0
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm9, ymm14, ymm9 
############## a_3 * b_3
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm6, ymm14, ymm6 
############## a_2 * b_3
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm7, ymm14, ymm7 
############## a_5 * b_3
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm4, ymm14, ymm4 
############## a_4 * b_3
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm5, ymm14, ymm5 
############## a_6 * b_3
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm3, ymm14, ymm3
############## a_7 * b_3
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm12, ymm14, ymm12
############## a_8 * b_3
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm11, ymm14, ymm11
############## a_9 * b_3
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm10, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 96] , ymm9


############## load    b_4
    vmovdqa ymm15, YMMWORD PTR [rdx + 64] 
############## perm = False
############## w/ adds
############## a_0 * b_4
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm8, ymm14, ymm8 
############## a_1 * b_4
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm7, ymm14, ymm7 
############## a_2 * b_4
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm6, ymm14, ymm6 
############## a_3 * b_4
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm5, ymm14, ymm5 
############## a_4 * b_4
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm4, ymm14, ymm4 
############## a_5 * b_4
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm3, ymm14, ymm3 
############## a_6 * b_4
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm12, ymm14, ymm12
############## a_7 * b_4
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm11, ymm14, ymm11
############## a_8 * b_4
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm10, ymm14, ymm10
############## a_9 * b_4
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm9, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 128] , ymm8


############## perm to b_5
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_5
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm6, ymm14, ymm6 
############## a_0 * b_5
############## read from regs
############## perm ymm0 to a_0
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm7, ymm14, ymm7 
############## a_3 * b_5
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm4, ymm14, ymm4 
############## a_2 * b_5
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm5, ymm14, ymm5 
############## a_5 * b_5
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm12, ymm14, ymm12 
############## a_4 * b_5
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm3, ymm14, ymm3 
############## a_6 * b_5
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm11, ymm14, ymm11
############## a_7 * b_5
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm10, ymm14, ymm10
############## a_8 * b_5
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm9, ymm14, ymm9
############## a_9 * b_5
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm8, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 160] , ymm7


############## load    b_6
    vmovdqa ymm15, YMMWORD PTR [rdx + 96] 
############## perm = False
############## w/ adds
############## a_0 * b_6
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm6, ymm14, ymm6 
############## a_1 * b_6
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm5, ymm14, ymm5 
############## a_2 * b_6
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm4, ymm14, ymm4 
############## a_3 * b_6
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm3, ymm14, ymm3 
############## a_4 * b_6
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm12, ymm14, ymm12 
############## a_5 * b_6
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm11, ymm14, ymm11 
############## a_6 * b_6
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm10, ymm14, ymm10
############## a_7 * b_6
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm9, ymm14, ymm9
############## a_8 * b_6
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm8, ymm14, ymm8
############## a_9 * b_6
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm7, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 192] , ymm6


############## perm to b_7
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_7
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm4, ymm14, ymm4 
############## a_0 * b_7
############## read from regs
############## perm ymm0 to a_0
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm5, ymm14, ymm5 
############## a_3 * b_7
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm12, ymm14, ymm12 
############## a_2 * b_7
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm3, ymm14, ymm3 
############## a_5 * b_7
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm10, ymm14, ymm10 
############## a_4 * b_7
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm11, ymm14, ymm11 
############## a_6 * b_7
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm9, ymm14, ymm9
############## a_7 * b_7
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm8, ymm14, ymm8
############## a_8 * b_7
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm7, ymm14, ymm7
############## a_9 * b_7
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm6, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 224] , ymm5


############## load    b_8
    vmovdqa ymm15, YMMWORD PTR [rdx + 128] 
############## perm = False
############## w/ adds
############## a_0 * b_8
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm4, ymm14, ymm4 
############## a_1 * b_8
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm3, ymm14, ymm3 
############## a_2 * b_8
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm12, ymm14, ymm12 
############## a_3 * b_8
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm11, ymm14, ymm11 
############## a_4 * b_8
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm10, ymm14, ymm10 
############## a_5 * b_8
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm9, ymm14, ymm9 
############## a_6 * b_8
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm8, ymm14, ymm8
############## a_7 * b_8
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm7, ymm14, ymm7
############## a_8 * b_8
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm6, ymm14, ymm6
############## a_9 * b_8
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm5, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 256] , ymm4


############## perm to b_9
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_9
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm12, ymm14, ymm12 
############## a_0 * b_9
############## read from regs
############## perm ymm0 to a_0
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm3, ymm14, ymm3 
############## a_3 * b_9
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm10, ymm14, ymm10 
############## a_2 * b_9
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm11, ymm14, ymm11 
############## a_5 * b_9
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm8, ymm14, ymm8 
############## a_4 * b_9
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm9, ymm14, ymm9 
############## a_6 * b_9
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm7, ymm14, ymm7
############## a_7 * b_9
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm6, ymm14, ymm6
############## a_8 * b_9
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm5, ymm14, ymm5
############## a_9 * b_9
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm4, ymm15, ymm13
    vmovdqa YMMWORD PTR [rdi + 288] , ymm3
############## write all the rest
    vmovdqa YMMWORD PTR [rdi + 320], ymm12
    vmovdqa YMMWORD PTR [rdi + 352], ymm11
    vmovdqa YMMWORD PTR [rdi + 384], ymm10
    vmovdqa YMMWORD PTR [rdi + 416], ymm9
    vmovdqa YMMWORD PTR [rdi + 448], ymm8
    vmovdqa YMMWORD PTR [rdi + 480], ymm7
    vmovdqa YMMWORD PTR [rdi + 512], ymm6
    vmovdqa YMMWORD PTR [rdi + 544], ymm5
    vmovdqa YMMWORD PTR [rdi + 576], ymm4
    ret

.global secsidh_internal_2047k221_carryVertical64_avx2
secsidh_internal_2047k221_carryVertical64_avx2:
        vmovdqa ymm1, ymmword ptr [rdi]
        vpsrad  ymm2, ymm1, 26
        vpbroadcastq    ymm0, qword ptr [rip + .base] # ymm0 = [67108863,67108863,67108863,67108863]
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 32]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 32], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 64]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 64], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 96]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 96], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 128]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 128], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 160]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 160], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 192]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 192], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 224]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 224], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 256]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 256], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 288]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 288], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 320]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 320], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 352]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 352], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 384]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 384], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 416]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 416], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 448]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 448], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 480]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 480], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 512]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 512], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 544]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm1, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 544], ymm1
        vpaddd  ymm1, ymm2, ymmword ptr [rdi + 576]
        vpsrad  ymm2, ymm1, 26
        vpand   ymm0, ymm1, ymm0
        vmovdqa ymmword ptr [rdi + 576], ymm0
        vpaddd  ymm0, ymm2, ymmword ptr [rdi + 608]
        vmovdqa ymmword ptr [rdi + 608], ymm0
        ret


.global secsidh_internal_2047k221_sub_avx2_32_4
secsidh_internal_2047k221_sub_avx2_32_4:
        vmovdqa ymm0, ymmword ptr [rdi]
        vmovdqa ymm1, ymmword ptr [rdi + 32]
        vmovdqa ymm2, ymmword ptr [rdi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymm3, ymmword ptr [rdi + 96]
        vmovdqa ymmword ptr [rdi], ymm0
        vpsubd  ymm0, ymm1, ymmword ptr [rsi + 32]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vpsubd  ymm0, ymm2, ymmword ptr [rsi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vpsubd  ymm0, ymm3, ymmword ptr [rsi + 96]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vzeroupper
        ret

.global secsidh_internal_2047k221_sub_avx2_32_8
secsidh_internal_2047k221_sub_avx2_32_8:
        vmovdqa ymm0, ymmword ptr [rdi]
        vmovdqa ymm1, ymmword ptr [rdi + 32]
        vmovdqa ymm2, ymmword ptr [rdi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymm3, ymmword ptr [rdi + 96]
        vmovdqa ymmword ptr [rdi], ymm0
        vpsubd  ymm0, ymm1, ymmword ptr [rsi + 32]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vpsubd  ymm0, ymm2, ymmword ptr [rsi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vpsubd  ymm0, ymm3, ymmword ptr [rsi + 96]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vzeroupper
        ret

.global secsidh_internal_2047k221_sub_avx2_32_16
secsidh_internal_2047k221_sub_avx2_32_16:
        vmovdqa ymm0, ymmword ptr [rdi]
        vmovdqa ymm1, ymmword ptr [rdi + 32]
        vmovdqa ymm2, ymmword ptr [rdi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymm3, ymmword ptr [rdi + 96]
        vmovdqa ymmword ptr [rdi], ymm0
        vpsubd  ymm0, ymm1, ymmword ptr [rsi + 32]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vpsubd  ymm0, ymm2, ymmword ptr [rsi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vpsubd  ymm0, ymm3, ymmword ptr [rsi + 96]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 256]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 288]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 320]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 320]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 320]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 352]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 352]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 352]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 384]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 384]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 384]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 416]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 416]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 416]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 448]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 448]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 448]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 480]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 480]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 480]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vzeroupper
        ret

.global secsidh_internal_2047k221_sub_avx2_32_32
secsidh_internal_2047k221_sub_avx2_32_32:
        vmovdqa ymm0, ymmword ptr [rdi]
        vmovdqa ymm1, ymmword ptr [rdi + 32]
        vmovdqa ymm2, ymmword ptr [rdi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymm3, ymmword ptr [rdi + 96]
        vmovdqa ymmword ptr [rdi], ymm0
        vpsubd  ymm0, ymm1, ymmword ptr [rsi + 32]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vpsubd  ymm0, ymm2, ymmword ptr [rsi + 64]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vpsubd  ymm0, ymm3, ymmword ptr [rsi + 96]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 256]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 288]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 320]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 320]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 320]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 352]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 352]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 352]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 384]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 384]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 384]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 416]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 416]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 416]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 448]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 448]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 448]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 480]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 480]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 480]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 512]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 512]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 512]
        vmovdqa ymmword ptr [rdi + 512], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 544]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 544]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 544]
        vmovdqa ymmword ptr [rdi + 544], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 576]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 576]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 576]
        vmovdqa ymmword ptr [rdi + 576], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 608]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 608]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 608]
        vmovdqa ymmword ptr [rdi + 608], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 640]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 640]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 640]
        vmovdqa ymmword ptr [rdi + 640], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 672]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 672]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 672]
        vmovdqa ymmword ptr [rdi + 672], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 704]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 704]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 704]
        vmovdqa ymmword ptr [rdi + 704], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 736]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 736]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 736]
        vmovdqa ymmword ptr [rdi + 736], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 768]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 768]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 768]
        vmovdqa ymmword ptr [rdi + 768], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 800]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 800]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 800]
        vmovdqa ymmword ptr [rdi + 800], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 832]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 832]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 832]
        vmovdqa ymmword ptr [rdi + 832], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 864]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 864]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 864]
        vmovdqa ymmword ptr [rdi + 864], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 896]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 896]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 896]
        vmovdqa ymmword ptr [rdi + 896], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 928]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 928]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 928]
        vmovdqa ymmword ptr [rdi + 928], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 960]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 960]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 960]
        vmovdqa ymmword ptr [rdi + 960], ymm0
        vmovdqa ymm0, ymmword ptr [rdi + 992]
        vpsubd  ymm0, ymm0, ymmword ptr [rsi + 992]
        vpsubd  ymm0, ymm0, ymmword ptr [rdx + 992]
        vmovdqa ymmword ptr [rdi + 992], ymm0
        vzeroupper
        ret        

.global secsidh_internal_2047k221_add_avx2_32_4
secsidh_internal_2047k221_add_avx2_32_4:
        vmovdqa ymm0, ymmword ptr [rdx]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 32]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vzeroupper
        ret        

.global secsidh_internal_2047k221_add_avx2_32_8
secsidh_internal_2047k221_add_avx2_32_8:
        vmovdqa ymm0, ymmword ptr [rdx]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 32]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vzeroupper
        ret     

.global secsidh_internal_2047k221_add_avx2_32_16
secsidh_internal_2047k221_add_avx2_32_16:
        vmovdqa ymm0, ymmword ptr [rdx]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 32]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 256]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 288]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 320]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 320]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 352]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 352]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 384]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 384]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 416]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 416]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 448]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 448]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 480]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 480]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vzeroupper
        ret           

.global secsidh_internal_2047k221_add_avx2_32_32
secsidh_internal_2047k221_add_avx2_32_32:
        vmovdqa ymm0, ymmword ptr [rdx]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 32]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 64]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 96]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 256]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 288]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 320]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 320]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 352]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 352]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 384]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 384]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 416]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 416]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 448]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 448]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 480]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 480]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 512]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 512]
        vmovdqa ymmword ptr [rdi + 512], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 544]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 544]
        vmovdqa ymmword ptr [rdi + 544], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 576]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 576]
        vmovdqa ymmword ptr [rdi + 576], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 608]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 608]
        vmovdqa ymmword ptr [rdi + 608], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 640]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 640]
        vmovdqa ymmword ptr [rdi + 640], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 672]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 672]
        vmovdqa ymmword ptr [rdi + 672], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 704]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 704]
        vmovdqa ymmword ptr [rdi + 704], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 736]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 736]
        vmovdqa ymmword ptr [rdi + 736], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 768]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 768]
        vmovdqa ymmword ptr [rdi + 768], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 800]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 800]
        vmovdqa ymmword ptr [rdi + 800], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 832]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 832]
        vmovdqa ymmword ptr [rdi + 832], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 864]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 864]
        vmovdqa ymmword ptr [rdi + 864], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 896]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 896]
        vmovdqa ymmword ptr [rdi + 896], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 928]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 928]
        vmovdqa ymmword ptr [rdi + 928], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 960]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 960]
        vmovdqa ymmword ptr [rdi + 960], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 992]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 992]
        vmovdqa ymmword ptr [rdi + 992], ymm0
        vzeroupper
        ret


.global secsidh_internal_2047k221_add_2x_avx2_32_4
secsidh_internal_2047k221_add_2x_avx2_32_4:
        vmovdqa ymm0, ymmword ptr [rsi + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 128]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 160]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 192]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 224]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vzeroupper
        ret        

.global secsidh_internal_2047k221_add_2x_avx2_32_8
secsidh_internal_2047k221_add_2x_avx2_32_8:
        vmovdqa ymm0, ymmword ptr [rsi + 256]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 256]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 288]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 288]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 320]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 320]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 352]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 352]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 384]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 384]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 416]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 416]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 448]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 448]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 480]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 480]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vzeroupper
        ret                


.global secsidh_internal_2047k221_add_2x_avx2_32_16
secsidh_internal_2047k221_add_2x_avx2_32_16:
        vmovdqa ymm0, ymmword ptr [rsi + 512]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi]
        vmovdqa ymmword ptr [rdi], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 512]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx]
        vmovdqa ymmword ptr [rdi + 512], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 544]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
        vmovdqa ymmword ptr [rdi + 32], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 544]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 32]
        vmovdqa ymmword ptr [rdi + 544], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 576]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 64]
        vmovdqa ymmword ptr [rdi + 64], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 576]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 64]
        vmovdqa ymmword ptr [rdi + 576], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 608]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 96]
        vmovdqa ymmword ptr [rdi + 96], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 608]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 96]
        vmovdqa ymmword ptr [rdi + 608], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 640]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 128]
        vmovdqa ymmword ptr [rdi + 128], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 640]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 128]
        vmovdqa ymmword ptr [rdi + 640], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 672]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 160]
        vmovdqa ymmword ptr [rdi + 160], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 672]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 160]
        vmovdqa ymmword ptr [rdi + 672], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 704]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 192]
        vmovdqa ymmword ptr [rdi + 192], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 704]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 192]
        vmovdqa ymmword ptr [rdi + 704], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 736]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 224]
        vmovdqa ymmword ptr [rdi + 224], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 736]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 224]
        vmovdqa ymmword ptr [rdi + 736], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 768]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 256]
        vmovdqa ymmword ptr [rdi + 256], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 768]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 256]
        vmovdqa ymmword ptr [rdi + 768], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 800]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 288]
        vmovdqa ymmword ptr [rdi + 288], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 800]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 288]
        vmovdqa ymmword ptr [rdi + 800], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 832]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 320]
        vmovdqa ymmword ptr [rdi + 320], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 832]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 320]
        vmovdqa ymmword ptr [rdi + 832], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 864]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 352]
        vmovdqa ymmword ptr [rdi + 352], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 864]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 352]
        vmovdqa ymmword ptr [rdi + 864], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 896]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 384]
        vmovdqa ymmword ptr [rdi + 384], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 896]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 384]
        vmovdqa ymmword ptr [rdi + 896], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 928]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 416]
        vmovdqa ymmword ptr [rdi + 416], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 928]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 416]
        vmovdqa ymmword ptr [rdi + 928], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 960]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 448]
        vmovdqa ymmword ptr [rdi + 448], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 960]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 448]
        vmovdqa ymmword ptr [rdi + 960], ymm0
        vmovdqa ymm0, ymmword ptr [rsi + 992]
        vpaddd  ymm0, ymm0, ymmword ptr [rsi + 480]
        vmovdqa ymmword ptr [rdi + 480], ymm0
        vmovdqa ymm0, ymmword ptr [rdx + 992]
        vpaddd  ymm0, ymm0, ymmword ptr [rdx + 480]
        vmovdqa ymmword ptr [rdi + 992], ymm0
        vzeroupper
        ret        

.global secsidh_internal_2047k221_add_2x_avx2_32_2
secsidh_internal_2047k221_add_2x_avx2_32_2:
    vmovdqa ymm0, ymmword ptr [rsi + 64]
    vpaddd  ymm0, ymm0, ymmword ptr [rsi]
    vmovdqa ymmword ptr [rdi], ymm0
    vmovdqa ymm0, ymmword ptr [rdx + 64]
    vpaddd  ymm0, ymm0, ymmword ptr [rdx]
    vmovdqa ymmword ptr [rdi + 64], ymm0
    vmovdqa ymm0, ymmword ptr [rsi + 96]
    vpaddd  ymm0, ymm0, ymmword ptr [rsi + 32]
    vmovdqa ymmword ptr [rdi + 32], ymm0
    vmovdqa ymm0, ymmword ptr [rdx + 96]
    vpaddd  ymm0, ymm0, ymmword ptr [rdx + 32]
    vmovdqa ymmword ptr [rdi + 96], ymm0
    vzeroupper
    ret


.global secsidh_internal_2047k221_squaring_interl
secsidh_internal_2047k221_squaring_interl:
############## load as much a's as possible
    vmovdqa ymm0, YMMWORD PTR [rsi + 0] 
    vmovdqa ymm1, YMMWORD PTR [rsi + 32] 
    vmovdqa ymm2, YMMWORD PTR [rsi + 64] 


############## load    b_0
    vmovdqa ymm15, YMMWORD PTR [rdx + 0] 
############## w/o adds
############## a_0 * b_0
############## read from regs
############## ymm0 = a_0
    vpmuldq ymm12 , ymm15, ymm0
############## a_1 * b_0
############## read from regs
############## perm ymm0 to a_1
    vpshufd ymm0, ymm0, 177
    vpmuldq ymm11 , ymm15, ymm0
    vpaddq ymm11, ymm11, ymm11    
############## a_2 * b_0
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm10 , ymm15, ymm1
    vpaddq ymm10, ymm10, ymm10    
############## a_3 * b_0
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm9 , ymm15, ymm1
    vpaddq ymm9, ymm9, ymm9    
############## a_4 * b_0
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm8 , ymm15, ymm2
    vpaddq ymm8, ymm8, ymm8    
############## a_5 * b_0
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm7 , ymm15, ymm2
    vpaddq ymm7, ymm7, ymm7    
############## a_6 * b_0
############## read from stack
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
############## load    a_6
    vpmuldq ymm6, ymm15, ymm13
    vpaddq ymm6, ymm6, ymm6    
############## a_7 * b_0
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm5, ymm15, ymm13
    vpaddq ymm5, ymm5, ymm5    
############## a_8 * b_0
############## read from stack
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
############## load    a_8
    vpmuldq ymm4, ymm15, ymm13
    vpaddq ymm4, ymm4, ymm4 
############## a_9 * b_0
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm3, ymm15, ymm13
    vpaddq ymm3, ymm3, ymm3     
    vmovdqu YMMWORD PTR [rdi + 0], ymm12
    vxorps ymm12, ymm12, ymm12


############## perm to b_1
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_1
############## read from regs
############## ymm0 = a_1
    vpmuldq ymm14, ymm15, ymm0
    vpaddq  ymm10, ymm14, ymm10 
############## a_0 * b_1
############## read from regs
############## perm ymm0 to a_0

############## a_3 * b_1
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm8, ymm14, ymm8
############## a_2 * b_1
############## read from regs
############## perm ymm1 to a_2
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm9, ymm14, ymm9 
############## a_5 * b_1
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm6, ymm14, ymm6 
############## a_4 * b_1
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm7, ymm14, ymm7 
############## a_6 * b_1
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm5, ymm14, ymm5
############## a_7 * b_1
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm4, ymm14, ymm4
############## a_8 * b_1
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm3, ymm14, ymm3
############## a_9 * b_1
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm12, ymm15, ymm13
    vpaddq ymm12, ymm12, ymm12
    vmovdqu YMMWORD PTR [rdi + 32] , ymm11
    vxorps ymm11, ymm11, ymm11


############## load    b_2
    vmovdqa ymm15, YMMWORD PTR [rdx + 32] 
############## perm = False
############## w/ adds
############## a_0 * b_2
############## read from regs
############## ymm0 = a_0

############## a_1 * b_2
############## read from regs
############## perm ymm0 to a_1

############## a_2 * b_2
############## read from regs
############## ymm1 = a_2
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm8, ymm14, ymm8 
############## a_3 * b_2
############## read from regs
############## perm ymm1 to a_3
    vpshufd ymm1, ymm1, 177
    vpmuldq ymm14, ymm15, ymm1
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm7, ymm14, ymm7 
############## a_4 * b_2
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm6, ymm14, ymm6 
############## a_5 * b_2
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm5, ymm14, ymm5 
############## a_6 * b_2
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm4, ymm14, ymm4
############## a_7 * b_2
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm3, ymm14, ymm3
############## a_8 * b_2
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm12, ymm14, ymm12
############## a_9 * b_2
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm11, ymm15, ymm13
    vpaddq ymm11, ymm11, ymm11
    vmovdqu YMMWORD PTR [rdi + 64] , ymm10
    vxorps ymm10, ymm10, ymm10


############## perm to b_3
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_3
############## read from regs
############## ymm0 = a_1

############## a_0 * b_3
############## read from regs
############## perm ymm0 to a_0

############## a_3 * b_3
############## read from regs
############## ymm1 = a_3
    vpmuldq ymm14, ymm15, ymm1
    vpaddq  ymm6, ymm14, ymm6 
############## a_2 * b_3
############## read from regs
############## perm ymm1 to a_2

############## a_5 * b_3
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm4, ymm14, ymm4 
############## a_4 * b_3
############## read from regs
############## perm ymm2 to a_4
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm5, ymm14, ymm5 
############## a_6 * b_3
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm3, ymm14, ymm3
############## a_7 * b_3
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm12, ymm14, ymm12
############## a_8 * b_3
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm11, ymm14, ymm11
############## a_9 * b_3
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm10, ymm15, ymm13
    vpaddq ymm10, ymm10, ymm10
    vmovdqu YMMWORD PTR [rdi + 96] , ymm9
    vxorps ymm9, ymm9, ymm9


############## load    b_4
    vmovdqa ymm15, YMMWORD PTR [rdx + 64] 
############## perm = False
############## w/ adds
############## a_0 * b_4
############## read from regs
############## ymm0 = a_0

############## a_1 * b_4
############## read from regs
############## perm ymm0 to a_1

############## a_2 * b_4
############## read from regs
############## ymm1 = a_2

############## a_3 * b_4
############## read from regs
############## perm ymm1 to a_3

############## a_4 * b_4
############## read from regs
############## ymm2 = a_4
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm4, ymm14, ymm4 
############## a_5 * b_4
############## read from regs
############## perm ymm2 to a_5
    vpshufd ymm2, ymm2, 177
    vpmuldq ymm14, ymm15, ymm2
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm3, ymm14, ymm3 
############## a_6 * b_4
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm12, ymm14, ymm12
############## a_7 * b_4
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm11, ymm14, ymm11
############## a_8 * b_4
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm10, ymm14, ymm10
############## a_9 * b_4
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm9, ymm15, ymm13
    vpaddq ymm9, ymm9, ymm9    
    vmovdqu YMMWORD PTR [rdi + 128] , ymm8
    vxorps ymm8, ymm8, ymm8


############## perm to b_5
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_5
############## read from regs
############## ymm0 = a_1

############## a_0 * b_5
############## read from regs
############## perm ymm0 to a_0

############## a_3 * b_5
############## read from regs
############## ymm1 = a_3

############## a_2 * b_5
############## read from regs
############## perm ymm1 to a_2

############## a_5 * b_5
############## read from regs
############## ymm2 = a_5
    vpmuldq ymm14, ymm15, ymm2
    vpaddq  ymm12, ymm14, ymm12 
############## a_4 * b_5
############## read from regs
############## perm ymm2 to a_4

############## a_6 * b_5
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm11, ymm14, ymm11
############## a_7 * b_5
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm10, ymm14, ymm10
############## a_8 * b_5
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm9, ymm14, ymm9
############## a_9 * b_5
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm8, ymm15, ymm13
    vpaddq ymm8, ymm8, ymm8
    vmovdqu YMMWORD PTR [rdi + 160] , ymm7
    vxorps ymm7, ymm7, ymm7


############## load    b_6
    vmovdqa ymm15, YMMWORD PTR [rdx + 96] 
############## perm = False
############## w/ adds
############## a_0 * b_6
############## read from regs
############## ymm0 = a_0

############## a_1 * b_6
############## read from regs
############## perm ymm0 to a_1

############## a_2 * b_6
############## read from regs
############## ymm1 = a_2

############## a_3 * b_6
############## read from regs
############## perm ymm1 to a_3

############## a_4 * b_6
############## read from regs
############## ymm2 = a_4

############## a_5 * b_6
############## read from regs
############## perm ymm2 to a_5

############## a_6 * b_6
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm10, ymm14, ymm10
############## a_7 * b_6
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm9, ymm14, ymm9
############## a_8 * b_6
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm8, ymm14, ymm8
############## a_9 * b_6
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm7, ymm15, ymm13
    vpaddq ymm7, ymm7, ymm7
    vmovdqu YMMWORD PTR [rdi + 192] , ymm6
    vxorps ymm6, ymm6, ymm6


############## perm to b_7
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_7
############## read from regs
############## ymm0 = a_1

############## a_0 * b_7
############## read from regs
############## perm ymm0 to a_0

############## a_3 * b_7
############## read from regs
############## ymm1 = a_3

############## a_2 * b_7
############## read from regs
############## perm ymm1 to a_2

############## a_5 * b_7
############## read from regs
############## ymm2 = a_5

############## a_4 * b_7
############## read from regs
############## perm ymm2 to a_4

############## a_6 * b_7
############## read from stack
############## load    a_6
    vmovdqa ymm13, YMMWORD PTR [rsi + 96]
############## a_7 * b_7
############## read from stack
############## perm to a_7
    vpshufd ymm13, ymm13, 177
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm8, ymm14, ymm8
############## a_8 * b_7
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq ymm14, ymm14, ymm14    
    vpaddq  ymm7, ymm14, ymm7
############## a_9 * b_7
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm6, ymm15, ymm13
    vpaddq ymm6, ymm6, ymm6    
    vmovdqu YMMWORD PTR [rdi + 224] , ymm5
    vxorps ymm5, ymm5, ymm5


############## load    b_8
    vmovdqa ymm15, YMMWORD PTR [rdx + 128] 
############## perm = False
############## w/ adds
############## a_0 * b_8
############## read from regs
############## ymm0 = a_0

############## a_1 * b_8
############## read from regs
############## perm ymm0 to a_1

############## a_2 * b_8
############## read from regs
############## ymm1 = a_2

############## a_3 * b_8
############## read from regs
############## perm ymm1 to a_3

############## a_4 * b_8
############## read from regs
############## ymm2 = a_4

############## a_5 * b_8
############## read from regs
############## perm ymm2 to a_5

############## a_6 * b_8
############## read from stack
############## load    a_6

############## a_7 * b_8
############## read from stack
############## perm to a_7

############## a_8 * b_8
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
    vpmuldq ymm14, ymm15, ymm13
    vpaddq  ymm6, ymm14, ymm6
############## a_9 * b_8
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm5, ymm15, ymm13
    vpaddq ymm5, ymm5, ymm5    
    vmovdqu YMMWORD PTR [rdi + 256] , ymm4
    vxorps ymm4, ymm4, ymm4


############## perm to b_9
    vpshufd ymm15, ymm15, 177
############## perm = True
############## w/ adds
############## a_1 * b_9
############## read from regs
############## ymm0 = a_1

############## a_0 * b_9
############## read from regs
############## perm ymm0 to a_0

############## a_3 * b_9
############## read from regs
############## ymm1 = a_3

############## a_2 * b_9
############## read from regs
############## perm ymm1 to a_2

############## a_5 * b_9
############## read from regs
############## ymm2 = a_5

############## a_4 * b_9
############## read from regs
############## perm ymm2 to a_4

############## a_6 * b_9
############## read from stack
############## load    a_6

############## a_7 * b_9
############## read from stack
############## perm to a_7

############## a_8 * b_9
############## read from stack
############## load    a_8
    vmovdqa ymm13, YMMWORD PTR [rsi + 128]
############## a_9 * b_9
############## read from stack
############## perm to a_9
    vpshufd ymm13, ymm13, 177
############## save add
    vpmuldq ymm4, ymm15, ymm13
    vmovdqu YMMWORD PTR [rdi + 288] , ymm3
    vxorps ymm3, ymm3, ymm3
############## write all the rest
    vmovdqu YMMWORD PTR [rdi + 320], ymm12
    vmovdqu YMMWORD PTR [rdi + 352], ymm11
    vmovdqu YMMWORD PTR [rdi + 384], ymm10
    vmovdqu YMMWORD PTR [rdi + 416], ymm9
    vmovdqu YMMWORD PTR [rdi + 448], ymm8
    vmovdqu YMMWORD PTR [rdi + 480], ymm7
    vmovdqu YMMWORD PTR [rdi + 512], ymm6
    vmovdqu YMMWORD PTR [rdi + 544], ymm5
    vmovdqu YMMWORD PTR [rdi + 576], ymm4
    ret




.macro add_16x16
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 15
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rdi + 16*8]
    adc rax, 0
    mov [rdi + 16*8], rax
.endm

.macro sub_d_34x32_woc
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

# intro
    mov rax, [rdi + 0*8]
    mov rbx, [rdi + 1*8]
    mov rcx, [rdi + 2*8]
    mov r8, [rdi + 3*8]
    mov r9, [rdi + 4*8]
    mov r10, [rdi + 5*8]
    mov r11, [rdi + 6*8]
    mov r12, [rdi + 7*8]
    mov r13, [rdi + 8*8]
    mov r14, [rdi + 9*8]
    mov r15, [rdi + 10*8]
# loop
    sub rax, [rsi + 0*8]
    sbb rbx, 0
    sub rax, [rdx + 0*8]
    sbb rbx, [rsi + 1*8]
    sbb rcx, 0
    sub rbx, [rdx + 1*8]
    sbb rcx, [rsi + 2*8]
    sbb r8, 0
    sub rcx, [rdx + 2*8]
    sbb r8, [rsi + 3*8]
    sbb r9, 0
    sub r8, [rdx + 3*8]
    sbb r9, [rsi + 4*8]
    sbb r10, 0
    sub r9, [rdx + 4*8]
    sbb r10, [rsi + 5*8]
    sbb r11, 0
    sub r10, [rdx + 5*8]
    sbb r11, [rsi + 6*8]
    sbb r12, 0
    sub r11, [rdx + 6*8]
    sbb r12, [rsi + 7*8]
    sbb r13, 0
    sub r12, [rdx + 7*8]
    sbb r13, [rsi + 8*8]
    sbb r14, 0
    sub r13, [rdx + 8*8]
    sbb r14, [rsi + 9*8]
    sbb r15, 0
    sub r14, [rdx + 9*8]
# ------------------
    mov [rdi + 0*8], rax
    mov [rdi + 1*8], rbx
    mov [rdi + 2*8], rcx
    mov [rdi + 3*8], r8
    mov [rdi + 4*8], r9
    mov [rdi + 5*8], r10
    mov [rdi + 6*8], r11
    mov [rdi + 7*8], r12
    mov [rdi + 8*8], r13
    mov [rdi + 9*8], r14
    mov rax, [rdi + 11*8]
    mov rbx, [rdi + 12*8]
    mov rcx, [rdi + 13*8]
    mov r8, [rdi + 14*8]
    mov r9, [rdi + 15*8]
    mov r10, [rdi + 16*8]
    mov r11, [rdi + 17*8]
    mov r12, [rdi + 18*8]
    mov r13, [rdi + 19*8]
    mov r14, [rdi + 20*8]
    sbb r15, [rsi + 10*8]
    sbb rax, 0
    sub r15, [rdx + 10*8]
    sbb rax, [rsi + 11*8]
    sbb rbx, 0
    sub rax, [rdx + 11*8]
    sbb rbx, [rsi + 12*8]
    sbb rcx, 0
    sub rbx, [rdx + 12*8]
    sbb rcx, [rsi + 13*8]
    sbb r8, 0
    sub rcx, [rdx + 13*8]
    sbb r8, [rsi + 14*8]
    sbb r9, 0
    sub r8, [rdx + 14*8]
    sbb r9, [rsi + 15*8]
    sbb r10, 0
    sub r9, [rdx + 15*8]
    sbb r10, [rsi + 16*8]
    sbb r11, 0
    sub r10, [rdx + 16*8]
    sbb r11, [rsi + 17*8]
    sbb r12, 0
    sub r11, [rdx + 17*8]
    sbb r12, [rsi + 18*8]
    sbb r13, 0
    sub r12, [rdx + 18*8]
    sbb r13, [rsi + 19*8]
    sbb r14, 0
    sub r13, [rdx + 19*8]
# ------------------
    mov [rdi + 10*8], r15
    mov [rdi + 11*8], rax
    mov [rdi + 12*8], rbx
    mov [rdi + 13*8], rcx
    mov [rdi + 14*8], r8
    mov [rdi + 15*8], r9
    mov [rdi + 16*8], r10
    mov [rdi + 17*8], r11
    mov [rdi + 18*8], r12
    mov [rdi + 19*8], r13
    mov r15, [rdi + 21*8]
    mov rax, [rdi + 22*8]
    mov rbx, [rdi + 23*8]
    mov rcx, [rdi + 24*8]
    mov r8, [rdi + 25*8]
    mov r9, [rdi + 26*8]
    mov r10, [rdi + 27*8]
    mov r11, [rdi + 28*8]
    mov r12, [rdi + 29*8]
    mov r13, [rdi + 30*8]
    sbb r14, [rsi + 20*8]
    sbb r15, 0
    sub r14, [rdx + 20*8]
    sbb r15, [rsi + 21*8]
    sbb rax, 0
    sub r15, [rdx + 21*8]
    sbb rax, [rsi + 22*8]
    sbb rbx, 0
    sub rax, [rdx + 22*8]
    sbb rbx, [rsi + 23*8]
    sbb rcx, 0
    sub rbx, [rdx + 23*8]
    sbb rcx, [rsi + 24*8]
    sbb r8, 0
    sub rcx, [rdx + 24*8]
    sbb r8, [rsi + 25*8]
    sbb r9, 0
    sub r8, [rdx + 25*8]
    sbb r9, [rsi + 26*8]
    sbb r10, 0
    sub r9, [rdx + 26*8]
    sbb r10, [rsi + 27*8]
    sbb r11, 0
    sub r10, [rdx + 27*8]
    sbb r11, [rsi + 28*8]
    sbb r12, 0
    sub r11, [rdx + 28*8]
    sbb r12, [rsi + 29*8]
    sbb r13, 0
    sub r12, [rdx + 29*8]
# ------------------
    mov [rdi + 20*8], r14
    mov [rdi + 21*8], r15
    mov [rdi + 22*8], rax
    mov [rdi + 23*8], rbx
    mov [rdi + 24*8], rcx
    mov [rdi + 25*8], r8
    mov [rdi + 26*8], r9
    mov [rdi + 27*8], r10
    mov [rdi + 28*8], r11
    mov [rdi + 29*8], r12
    mov r14, [rdi + 31*8]
    mov r15, [rdi + 32*8]
    sbb r13, [rsi + 30*8]
    sbb r14, 0
    sub r13, [rdx + 30*8]
    sbb r14, [rsi + 31*8]
    sbb r15, 0
    sub r14, [rdx + 31*8]
# ------------------
    mov [rdi + 30*8], r13
    mov [rdi + 31*8], r14
# outro
    sbb r15, 0
    mov [rdi + 32*8], r15
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

.endm

.macro add_34x33
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 32
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rsi + 8*33]
    adc rax, 0
    mov [rdi + 8*33], rax
.endm

.macro add_8x8
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 7
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rdi + 8*8]
    adc rax, 0
    mov [rdi + 8*8], rax
.endm

.macro sub_d_18x16_woc
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

# intro
    mov rax, [rdi + 0*8]
    mov rbx, [rdi + 1*8]
    mov rcx, [rdi + 2*8]
    mov r8, [rdi + 3*8]
    mov r9, [rdi + 4*8]
    mov r10, [rdi + 5*8]
    mov r11, [rdi + 6*8]
    mov r12, [rdi + 7*8]
    mov r13, [rdi + 8*8]
    mov r14, [rdi + 9*8]
    mov r15, [rdi + 10*8]
# loop
    sub rax, [rsi + 0*8]
    sbb rbx, 0
    sub rax, [rdx + 0*8]
    sbb rbx, [rsi + 1*8]
    sbb rcx, 0
    sub rbx, [rdx + 1*8]
    sbb rcx, [rsi + 2*8]
    sbb r8, 0
    sub rcx, [rdx + 2*8]
    sbb r8, [rsi + 3*8]
    sbb r9, 0
    sub r8, [rdx + 3*8]
    sbb r9, [rsi + 4*8]
    sbb r10, 0
    sub r9, [rdx + 4*8]
    sbb r10, [rsi + 5*8]
    sbb r11, 0
    sub r10, [rdx + 5*8]
    sbb r11, [rsi + 6*8]
    sbb r12, 0
    sub r11, [rdx + 6*8]
    sbb r12, [rsi + 7*8]
    sbb r13, 0
    sub r12, [rdx + 7*8]
    sbb r13, [rsi + 8*8]
    sbb r14, 0
    sub r13, [rdx + 8*8]
    sbb r14, [rsi + 9*8]
    sbb r15, 0
    sub r14, [rdx + 9*8]
# ------------------
    mov [rdi + 0*8], rax
    mov [rdi + 1*8], rbx
    mov [rdi + 2*8], rcx
    mov [rdi + 3*8], r8
    mov [rdi + 4*8], r9
    mov [rdi + 5*8], r10
    mov [rdi + 6*8], r11
    mov [rdi + 7*8], r12
    mov [rdi + 8*8], r13
    mov [rdi + 9*8], r14
    mov rax, [rdi + 11*8]
    mov rbx, [rdi + 12*8]
    mov rcx, [rdi + 13*8]
    mov r8, [rdi + 14*8]
    mov r9, [rdi + 15*8]
    mov r10, [rdi + 16*8]
    sbb r15, [rsi + 10*8]
    sbb rax, 0
    sub r15, [rdx + 10*8]
    sbb rax, [rsi + 11*8]
    sbb rbx, 0
    sub rax, [rdx + 11*8]
    sbb rbx, [rsi + 12*8]
    sbb rcx, 0
    sub rbx, [rdx + 12*8]
    sbb rcx, [rsi + 13*8]
    sbb r8, 0
    sub rcx, [rdx + 13*8]
    sbb r8, [rsi + 14*8]
    sbb r9, 0
    sub r8, [rdx + 14*8]
    sbb r9, [rsi + 15*8]
    sbb r10, 0
    sub r9, [rdx + 15*8]
# ------------------
    mov [rdi + 10*8], r15
    mov [rdi + 11*8], rax
    mov [rdi + 12*8], rbx
    mov [rdi + 13*8], rcx
    mov [rdi + 14*8], r8
    mov [rdi + 15*8], r9
# outro
    sbb r10, 0
    mov [rdi + 16*8], r10
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

.endm

.macro add_18x17
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 16
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rsi + 8*17]
    adc rax, 0
    mov [rdi + 8*17], rax
.endm

.macro mult_8x8
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

# intro 
    mov rbp, rdx
    mov rdx, [rbp]
    mulx r14, rcx, [rsi + 0*8]
    mov [rdi + 0*8], rcx
    mulx r13, rax, [rsi + 1*8]
    add r14, rax
    mulx r12, rax, [rsi + 2*8]
    adc r13, rax
    mulx r11, rax, [rsi + 3*8]
    adc r12, rax
    mulx r10, rax, [rsi + 4*8]
    adc r11, rax
    mulx r9, rax, [rsi + 5*8]
    adc r10, rax
    mulx r8, rax, [rsi + 6*8]
    adc r9, rax
    mulx rcx, rax, [rsi + 7*8]
    adc r8, rax
    adc rcx, 0
# loop i = 1
    mov rdx, [rbp + 1*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r14, rax
    adox r13, rbx
    mov [rdi + 1*8], r14
    mov r14, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx rcx, rax
    adox r14, rbx
    adc r14, 0
# loop i = 2
    mov rdx, [rbp + 2*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r13, rax
    adox r12, rbx
    mov [rdi + 2*8], r13
    mov r13, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r14, rax
    adox r13, rbx
    adc r13, 0
# loop i = 3
    mov rdx, [rbp + 3*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r12, rax
    adox r11, rbx
    mov [rdi + 3*8], r12
    mov r12, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r13, rax
    adox r12, rbx
    adc r12, 0
# loop i = 4
    mov rdx, [rbp + 4*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r11, rax
    adox r10, rbx
    mov [rdi + 4*8], r11
    mov r11, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r12, rax
    adox r11, rbx
    adc r11, 0
# loop i = 5
    mov rdx, [rbp + 5*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r10, rax
    adox r9, rbx
    mov [rdi + 5*8], r10
    mov r10, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r11, rax
    adox r10, rbx
    adc r10, 0
# loop i = 6
    mov rdx, [rbp + 6*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r9, rax
    adox r8, rbx
    mov [rdi + 6*8], r9
    mov r9, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r10, rax
    adox r9, rbx
    adc r9, 0
# loop i = 7
    mov rdx, [rbp + 7*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r8, rax
    adox rcx, rbx
    mov [rdi + 7*8], r8
    mov r8, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx rcx, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r9, rax
    adox r8, rbx
    adc r8, 0
# outro
    mov [rdi + 8*8], rcx
    mov [rdi + 9*8], r14
    mov [rdi + 10*8], r13
    mov [rdi + 11*8], r12
    mov [rdi + 12*8], r11
    mov [rdi + 13*8], r10
    mov [rdi + 14*8], r9
    mov [rdi + 15*8], r8
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

.endm

.macro mult_9x9
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

# intro 
    mov rbp, rdx
    mov rdx, [rbp]
    mulx r15, rcx, [rsi + 0*8]
    mov [rdi + 0*8], rcx
    mulx r14, rax, [rsi + 1*8]
    add r15, rax
    mulx r13, rax, [rsi + 2*8]
    adc r14, rax
    mulx r12, rax, [rsi + 3*8]
    adc r13, rax
    mulx r11, rax, [rsi + 4*8]
    adc r12, rax
    mulx r10, rax, [rsi + 5*8]
    adc r11, rax
    mulx r9, rax, [rsi + 6*8]
    adc r10, rax
    mulx r8, rax, [rsi + 7*8]
    adc r9, rax
    mulx rcx, rax, [rsi + 8*8]
    adc r8, rax
    adc rcx, 0
# loop i = 1
    mov rdx, [rbp + 1*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r15, rax
    adox r14, rbx
    mov [rdi + 1*8], r15
    mov r15, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx rcx, rax
    adox r15, rbx
    adc r15, 0
# loop i = 2
    mov rdx, [rbp + 2*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r14, rax
    adox r13, rbx
    mov [rdi + 2*8], r14
    mov r14, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r15, rax
    adox r14, rbx
    adc r14, 0
# loop i = 3
    mov rdx, [rbp + 3*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r13, rax
    adox r12, rbx
    mov [rdi + 3*8], r13
    mov r13, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r14, rax
    adox r13, rbx
    adc r13, 0
# loop i = 4
    mov rdx, [rbp + 4*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r12, rax
    adox r11, rbx
    mov [rdi + 4*8], r12
    mov r12, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r13, rax
    adox r12, rbx
    adc r12, 0
# loop i = 5
    mov rdx, [rbp + 5*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r11, rax
    adox r10, rbx
    mov [rdi + 5*8], r11
    mov r11, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r12, rax
    adox r11, rbx
    adc r11, 0
# loop i = 6
    mov rdx, [rbp + 6*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r10, rax
    adox r9, rbx
    mov [rdi + 6*8], r10
    mov r10, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r9, rax
    adox r8, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r11, rax
    adox r10, rbx
    adc r10, 0
# loop i = 7
    mov rdx, [rbp + 7*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r9, rax
    adox r8, rbx
    mov [rdi + 7*8], r9
    mov r9, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx r8, rax
    adox rcx, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r10, rax
    adox r9, rbx
    adc r9, 0
# loop i = 8
    mov rdx, [rbp + 8*8]
    mulx rbx, rax, [rsi + 0*8]
    adcx r8, rax
    adox rcx, rbx
    mov [rdi + 8*8], r8
    mov r8, 0
    mulx rbx, rax, [rsi + 1*8]
    adcx rcx, rax
    adox r15, rbx
    mulx rbx, rax, [rsi + 2*8]
    adcx r15, rax
    adox r14, rbx
    mulx rbx, rax, [rsi + 3*8]
    adcx r14, rax
    adox r13, rbx
    mulx rbx, rax, [rsi + 4*8]
    adcx r13, rax
    adox r12, rbx
    mulx rbx, rax, [rsi + 5*8]
    adcx r12, rax
    adox r11, rbx
    mulx rbx, rax, [rsi + 6*8]
    adcx r11, rax
    adox r10, rbx
    mulx rbx, rax, [rsi + 7*8]
    adcx r10, rax
    adox r9, rbx
    mulx rbx, rax, [rsi + 8*8]
    adcx r9, rax
    adox r8, rbx
    adc r8, 0
# outro
    mov [rdi + 9*8], rcx
    mov [rdi + 10*8], r15
    mov [rdi + 11*8], r14
    mov [rdi + 12*8], r13
    mov [rdi + 13*8], r12
    mov [rdi + 14*8], r11
    mov [rdi + 15*8], r10
    mov [rdi + 16*8], r9
    mov [rdi + 17*8], r8
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

.endm

.macro mult_16x16
push    r14
xor     eax, eax
mov     ecx, 18
push    r13
lea     r13, [rsi+64]
push    r12
mov     r12, rdx
mov     rdx, r13
push    rbp
lea     r14, [r12+64]
mov     rbp, rsi
push    rbx
mov     rbx, rdi
sub     rsp, 288
mov     rdi, rsp
rep stosq
lea     rdi, [rsp+144]
mov     ecx, 18
rep stosq
mov     rdi, rsp
add_8x8
mov     rdx, r14
mov     rsi, r12
xor     eax, eax
lea     rdi, [rsp+72]
add_8x8
mov     rdx, r12
mov     rsi, rbp
mov     rdi, rbx
mult_8x8
lea     r12, [rbx+128]
mov     rdx, rsp
lea     rsi, [rsp+72]
lea     rdi, [rsp+144]
mult_9x9
mov     rdx, r14
mov     rsi, r13
mov     rdi, r12
mult_8x8
mov     rdx, r12
mov     rsi, rbx
xor     eax, eax
lea     rdi, [rsp+144]
sub_d_18x16_woc
lea     rdi, [rbx+64]
lea     rdx, [rsp+144]
xor     eax, eax
mov     rsi, rdi
add_18x17
add     rsp, 288
pop     rbx
pop     rbp
pop     r12
pop     r13
pop     r14
.endm

.macro add_9x8
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 7
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rsi + 8*8]
    adc rax, 0
    mov [rdi + 8*8], rax
.endm

.macro sub_d_18x18_woc
# push
    push rbx
    push rbp
    push rsi
    push r12
    push r13
    push r14
    push r15

# intro
    mov rax, [rdi + 0*8]
    mov rbx, [rdi + 1*8]
    mov rcx, [rdi + 2*8]
    mov r8, [rdi + 3*8]
    mov r9, [rdi + 4*8]
    mov r10, [rdi + 5*8]
    mov r11, [rdi + 6*8]
    mov r12, [rdi + 7*8]
    mov r13, [rdi + 8*8]
    mov r14, [rdi + 9*8]
    mov r15, [rdi + 10*8]
# loop
# ------------------
    sub rax, [rsi + 0*8]
    sbb rbx, 0
    sub rax, [rdx + 0*8]
    sbb rbx, [rsi + 1*8]
    sbb rcx, 0
    sub rbx, [rdx + 1*8]
    sbb rcx, [rsi + 2*8]
    sbb r8, 0
    sub rcx, [rdx + 2*8]
    sbb r8, [rsi + 3*8]
    sbb r9, 0
    sub r8, [rdx + 3*8]
    sbb r9, [rsi + 4*8]
    sbb r10, 0
    sub r9, [rdx + 4*8]
    sbb r10, [rsi + 5*8]
    sbb r11, 0
    sub r10, [rdx + 5*8]
    sbb r11, [rsi + 6*8]
    sbb r12, 0
    sub r11, [rdx + 6*8]
    sbb r12, [rsi + 7*8]
    sbb r13, 0
    sub r12, [rdx + 7*8]
    sbb r13, [rsi + 8*8]
    sbb r14, 0
    sub r13, [rdx + 8*8]
    sbb r14, [rsi + 9*8]
    sbb r15, 0
    sub r14, [rdx + 9*8]
# ------------------
    mov [rdi + 0*8], rax
    mov [rdi + 1*8], rbx
    mov [rdi + 2*8], rcx
    mov [rdi + 3*8], r8
    mov [rdi + 4*8], r9
    mov [rdi + 5*8], r10
    mov [rdi + 6*8], r11
    mov [rdi + 7*8], r12
    mov [rdi + 8*8], r13
    mov [rdi + 9*8], r14
# last loop
# ------------------
    mov rax, [rdi + 11*8]
    mov rbx, [rdi + 12*8]
    mov rcx, [rdi + 13*8]
    mov r8, [rdi + 14*8]
    mov r9, [rdi + 15*8]
    mov r10, [rdi + 16*8]
    mov r11, [rdi + 17*8]
# ------------------
    sbb r15, [rsi + 10*8]
    sbb rax, 0
    sub r15, [rdx + 10*8]
    sbb rax, [rsi + 11*8]
    sbb rbx, 0
    sub rax, [rdx + 11*8]
    sbb rbx, [rsi + 12*8]
    sbb rcx, 0
    sub rbx, [rdx + 12*8]
    sbb rcx, [rsi + 13*8]
    sbb r8, 0
    sub rcx, [rdx + 13*8]
    sbb r8, [rsi + 14*8]
    sbb r9, 0
    sub r8, [rdx + 14*8]
    sbb r9, [rsi + 15*8]
    sbb r10, 0
    sub r9, [rdx + 15*8]
# ------------------
    mov [rdi + 10*8], r15
    mov [rdi + 11*8], rax
    mov [rdi + 12*8], rbx
    mov [rdi + 13*8], rcx
    mov [rdi + 14*8], r8
    mov [rdi + 15*8], r9
    mov [rdi + 16*8], r10
# outro
    sbb r10, 0
    sub r10, [rsi + 16*8]
    sbb r11, 0
    sub r11, [rsi + 17*8]
    mov [rdi + 16*8], r10
    mov [rdi + 17*8], r11
# pop
    pop r15
    pop r14
    pop r13
    pop r12
    pop rsi
    pop rbp
    pop rbx

.endm

.macro add_19x18
# intro
    mov rax, [rsi + 0]
    add rax, [rdx + 0]
    mov [rdi + 0], rax
# loop
    .set k, 1
    .rept 17
        mov rax, [rsi + 8*k]
        adc rax, [rdx + 8*k]
        mov [rdi + 8*k], rax
        .set k, k+1
    .endr
# outro
    mov rax, [rsi + 8*18]
    adc rax, 0
    mov [rdi + 8*18], rax
.endm

.macro mult_17x17
push    r14
xor     eax, eax
mov     ecx, 18
push    r13
lea     r13, [rsi+64]
push    r12
mov     r12, rdx
mov     rdx, rsi
push    rbp
lea     r14, [r12+64]
mov     rbp, rsi
mov     rsi, r13
push    rbx
mov     rbx, rdi
sub     rsp, 288
mov     rdi, rsp
rep stosq
lea     rdi, [rsp+144]
mov     ecx, 18
rep stosq
mov     rdi, rsp
add_9x8
mov     rdx, r12
mov     rsi, r14
lea     rdi, [rsp+72]
xor     eax, eax
add_9x8
mov     rdx, r12
mov     rsi, rbp
mov     rdi, rbx
xor     eax, eax
lea     rbp, [rbx+128]
mult_8x8
mov     rdx, rsp
lea     rsi, [rsp+72]
xor     eax, eax
lea     rdi, [rsp+144]
mult_9x9
mov     rdx, r14
mov     rsi, r13
mov     rdi, rbp
xor     eax, eax
mult_9x9
mov     rdx, rbx
mov     rsi, rbp
xor     eax, eax
lea     rdi, [rsp+144]
sub_d_18x18_woc
lea     rdi, [rbx+64]
lea     rdx, [rsp+144]
xor     eax, eax
mov     rsi, rdi
add_19x18
add     rsp, 288
pop     rbx
pop     rbp
pop     r12
pop     r13
pop     r14
.endm

.macro mult_32x32
push    r14
xor     eax, eax
mov     ecx, 34
push    r13
lea     r13, [rsi+128]
push    r12
mov     r12, rdx
mov     rdx, r13
push    rbp
lea     r14, [r12+128]
mov     rbp, rsi
push    rbx
mov     rbx, rdi
sub     rsp, 544
mov     rdi, rsp
rep stosq
lea     rdi, [rsp+272]
mov     ecx, 34
rep stosq
mov     rdi, rsp
add_16x16
mov     rdx, r14
mov     rsi, r12
xor     eax, eax
lea     rdi, [rsp+136]
add_16x16
mov     rdx, r12
mov     rsi, rbp
mov     rdi, rbx
mult_16x16
lea     r12, [rbx+256]
mov     rdx, rsp
lea     rsi, [rsp+136]
lea     rdi, [rsp+272]
mult_17x17
mov     rdx, r14
mov     rsi, r13
mov     rdi, r12
mult_16x16
mov     rdx, r12
mov     rsi, rbx
xor     eax, eax
lea     rdi, [rsp+272]
sub_d_34x32_woc
lea     rdi, [rbx+128]
lea     rdx, [rsp+272]
xor     eax, eax
mov     rsi, rdi
add_34x33
add     rsp, 544
pop     rbx
pop     rbp
pop     r12
pop     r13
pop     r14
.endm

.global secsidh_internal_2047k221_fp_mult_32x32
secsidh_internal_2047k221_fp_mult_32x32:
    mult_32x32
    ret

.global secsidh_internal_2047k221_fp_cmov
secsidh_internal_2047k221_fp_cmov:
        mov     eax, edx
        neg     rax
        vmovq   xmm0, rax
        vpbroadcastq    ymm0, xmm0
        vpandn  ymm1, ymm0, ymmword ptr [rdi]
        vpand   ymm2, ymm0, ymmword ptr [rsi]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 32]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 32]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 32], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 64]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 64]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 64], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 96]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 96]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 96], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 128]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 128]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 128], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 160]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 160]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 160], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 192]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 192]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 192], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 224]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 224]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 224], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 256]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 256]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 256], ymm1
        vpandn  ymm1, ymm0, ymmword ptr [rdi + 288]
        vpand   ymm2, ymm0, ymmword ptr [rsi + 288]
        vpor    ymm1, ymm2, ymm1
        vmovdqa ymmword ptr [rdi + 288], ymm1
        vzeroupper
        ret

# .global secsidh_internal_2047k221_fp_cmov
# secsidh_internal_2047k221_fp_cmov:
#     movzx rax, dl
#     neg rax
#     .set k, 0
#     .rept baselimbs
#         mov rcx, [rdi + 4*k]
#         mov rdx, [rsi + 4*k]
#         xor rdx, rcx
#         and rdx, rax
#         xor rcx, rdx
#         mov [rdi + 4*k], rcx
#         .set k, k+1
#     .endr
#     ret

